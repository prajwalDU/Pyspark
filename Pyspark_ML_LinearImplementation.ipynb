{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbC3HsvlQ8zczJIsoSZICT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajwalDU/Pyspark/blob/main/Pyspark_ML_LinearImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. DBFS is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n",
        "\n",
        "This notebook is written in Python so the default cell type is Python. However, you can use different languages by using the %LANGUAGE syntax. Python, Scala, SQL, and R are all supported."
      ],
      "metadata": {
        "id": "zxD2ju7Ien9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File location and type\n",
        "file_location = \"/FileStore/tables/tips.csv\"\n",
        "file_type = \"csv\"\n",
        "\n",
        "# The applied options are for CSV files. For other file types, these will be ignored.\n",
        "df =spark.read.csv(file_location,header=True,inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "ukmihsdceqKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "bskuBx1meqHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "y2QmDezKeqEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Handling Categorical Features\n",
        "from pyspark.ml.feature import StringIndexer"
      ],
      "metadata": {
        "id": "JpEvK0lXeqBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "SrqXZJ-Bep-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer=StringIndexer(inputCol=\"sex\",outputCol=\"sex_indexed\")\n",
        "df_r=indexer.fit(df).transform(df)\n",
        "df_r.show()"
      ],
      "metadata": {
        "id": "8Wg15gpJep77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer=StringIndexer(inputCols=[\"smoker\",\"day\",\"time\"],outputCols=[\"smoker_indexed\",\"day_indexed\",\n",
        "                                                                  \"time_index\"])\n",
        "df_r=indexer.fit(df_r).transform(df_r)\n",
        "df_r.show()"
      ],
      "metadata": {
        "id": "fEntXa6rep5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_r.columns"
      ],
      "metadata": {
        "id": "EYRSYGX9ep2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "featureassembler=VectorAssembler(inputCols=['tip','size','sex_indexed','smoker_indexed','day_indexed',\n",
        "                          'time_index'],outputCol=\"Independent Features\")\n",
        "output=featureassembler.transform(df_r)"
      ],
      "metadata": {
        "id": "sm79bUvLepyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.select('Independent Features').show()"
      ],
      "metadata": {
        "id": "9qUiPcgDepvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.show()"
      ],
      "metadata": {
        "id": "Petc9U8Repq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data=output.select(\"Independent Features\",\"total_bill\")"
      ],
      "metadata": {
        "id": "-mEWnkJzepoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data.show()"
      ],
      "metadata": {
        "id": "a7PWkIiXeplX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWirusvoeFE4"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "##train test split\n",
        "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
        "regressor=LinearRegression(featuresCol='Independent Features', labelCol='total_bill')\n",
        "regressor=regressor.fit(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.coefficients"
      ],
      "metadata": {
        "id": "BbpMCeRafejJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.intercept"
      ],
      "metadata": {
        "id": "Kl85S-2ffeaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Predictions\n",
        "pred_results=regressor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "kwW_6mcmfeOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Final comparison\n",
        "pred_results.predictions.show()"
      ],
      "metadata": {
        "id": "uo55tEXcfeLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PErformance Metrics\n",
        "pred_results.r2,pred_results.meanAbsoluteError,pred_results.meanSquaredError"
      ],
      "metadata": {
        "id": "de3jGQSHfeIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}