{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KKKnyE5i_gd044za0WXDG3GmQN_QnElL",
      "authorship_tag": "ABX9TyMjuPEulZhQkf0rVOXSCz8q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajwalDU/Pyspark/blob/main/Pyspark_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pyspark DataFrame = It is a data structure, you know inside that we perform varies find of data structure.\n",
        "\n",
        "EX : pyspark.sql.dataframe.DataFrame "
      ],
      "metadata": {
        "id": "ziwv4dfwPP3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMSXjvLpZfiI",
        "outputId": "b69938bc-ad1e-4466-d24e-87aa096fec53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=4045ecc627d83b74ae639bc3df880ebe2b14798bad740e61f0125e776f0eb87c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('/content/drive/MyDrive/almabetter/AlmaX/pyspark/test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "WqatiOHtecSf",
        "outputId": "69e45a92-09be-43e8-e8c7-b84aca5db1d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      name  age\n",
              "0  prajwal   23\n",
              "1   vishal   25\n",
              "2    pooja   29\n",
              "3   sushma   48"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa3de28b-39df-4032-b198-6803c5748bc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>prajwal</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vishal</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pooja</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sushma</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa3de28b-39df-4032-b198-6803c5748bc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa3de28b-39df-4032-b198-6803c5748bc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa3de28b-39df-4032-b198-6803c5748bc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "TiQK8IOshGhR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Practice').getOrCreate()"
      ],
      "metadata": {
        "id": "fK2ul1KWhtSd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "pszdXWqliiPQ",
        "outputId": "894e50df-0360-436e-e959-6298c9f4b980"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f56a2ac96a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ac5eb336afeb:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('/content/drive/MyDrive/almabetter/AlmaX/pyspark/test.csv')"
      ],
      "metadata": {
        "id": "aQbgZroihtPe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WDe4GG6Bk9Z",
        "outputId": "65b17a14-109c-411b-c660-122ccea8b689"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark1 = spark.read.option('header', 'true').csv('/content/drive/MyDrive/almabetter/AlmaX/pyspark/no null data.csv')"
      ],
      "metadata": {
        "id": "v4ni5z5XhtMe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark1.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsViwLL1NKEZ",
        "outputId": "ee4a9ac0-5a3e-4d06-8a5a-28feca128887"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: string (nullable = true)\n",
            " |-- Experience: string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9ea7TIpyCUT",
        "outputId": "267963db-0270-49d0-b68a-e3e300be75d3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|Prajwal| 23|         6| 60000|\n",
            "| Vishal| 26|         8| 50000|\n",
            "|  pooja| 29|         7|  4000|\n",
            "| Sushma| 48|        15| 70000|\n",
            "| nayana| 23|         2| 30000|\n",
            "| Bacchu|  4|         5|     0|\n",
            "|   Sonu| 25|         4| 45000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2 = spark.read.option('header', 'true').csv('/content/drive/MyDrive/almabetter/AlmaX/pyspark/New one CSV.csv', inferSchema=True)"
      ],
      "metadata": {
        "id": "yvAZYj0NL0-t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.printSchema()"
      ],
      "metadata": {
        "id": "i_ux5YlFhtA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aab09c9-5a3a-4900-efc1-a016300e820f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark1)"
      ],
      "metadata": {
        "id": "LXAqaZJ2htGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771b77b7-cca4-4341-ed78-9e8d11b2b925"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark1.head(3)"
      ],
      "metadata": {
        "id": "WlOc8Tj4htD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf38cc18-e391-4436-858b-2debd8516f47"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Prajwal', Age='23', Experience='6', Salary='60000'),\n",
              " Row(Name='Vishal', Age='26', Experience='8', Salary='50000'),\n",
              " Row(Name='pooja', Age='29', Experience='7', Salary='4000')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('/content/drive/MyDrive/almabetter/AlmaX/pyspark/New one CSV.csv', header=True, inferSchema=True)\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "id": "z-gQRmwMhs-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63b0d6f-3901-41c4-ecdc-61c4cb299879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|Prajwal|  23|         6| 60000|\n",
            "| Vishal|  26|         8| 50000|\n",
            "|  pooja|  29|         7|  4000|\n",
            "| Sushma|  48|        15|  null|\n",
            "| nayana|  23|         2| 30000|\n",
            "| Bacchu|   4|      null|  null|\n",
            "|   Sonu|  25|         4| 45000|\n",
            "|   null|null|      null| 35000|\n",
            "|   null|  36|        10| 38000|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.columns"
      ],
      "metadata": {
        "id": "MuEQ_hoOhs7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91301bd2-bfe9-4564-9e9c-91755aa7fcb9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "id": "V60juuF6hs4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a1c15f9-a596-4391-b98b-8188ba7d10cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='prajwal', age=23),\n",
              " Row(name='vishal', age=25),\n",
              " Row(name='pooja', age=29)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark1.select('Name')"
      ],
      "metadata": {
        "id": "dA64_5Dphs1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4869f42c-8ba8-4d7f-960f-1c77874ceead"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* If we want to add multiple colums we write column name inside the square bracket([]).\n",
        "\n",
        "* In pyspark slicing not work"
      ],
      "metadata": {
        "id": "Dlfeszh6QpPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2['Name']"
      ],
      "metadata": {
        "id": "hnk5ji-7hsyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0de5ab-4c9f-4319-ad31-fc24c0d45643"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'Name'>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It just tells us the particular variable refers to. In pandas use like this."
      ],
      "metadata": {
        "id": "yZYt9J_sRZRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.dtypes"
      ],
      "metadata": {
        "id": "a1spC97bhswS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33773638-80da-4276-fdf4-57701f26cedd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe()"
      ],
      "metadata": {
        "id": "d8SpHPV0hstf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72938608-083b-4b2b-fdc2-4b70c629768d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, name: string, age: string]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ecAmSQtR6IF",
        "outputId": "88f010c4-3f24-4d63-b1ee-cd40b8aef178"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-----------------+------------------+\n",
            "|summary|  Name|               Age|       Experience|            Salary|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "|  count|     7|                 8|                7|                 7|\n",
            "|   mean|  null|             26.75|7.428571428571429| 37428.57142857143|\n",
            "| stddev|  null|12.487136238088036|4.237025012007948|17812.515664153514|\n",
            "|    min|Bacchu|                 4|                2|              4000|\n",
            "|    max| pooja|                48|               15|             60000|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.withColumn('Experience After 2 years', df_pyspark2['age']+2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5lux9dLR6Fq",
        "outputId": "259cf85f-d55f-490a-ec2d-93ea3ec0d9f8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+------------------------+\n",
            "|   Name| Age|Experience|Salary|Experience After 2 years|\n",
            "+-------+----+----------+------+------------------------+\n",
            "|Prajwal|  23|         6| 60000|                      25|\n",
            "| Vishal|  26|         8| 50000|                      28|\n",
            "|  pooja|  29|         7|  4000|                      31|\n",
            "| Sushma|  48|        15|  null|                      50|\n",
            "| nayana|  23|         2| 30000|                      25|\n",
            "| Bacchu|   4|      null|  null|                       6|\n",
            "|   Sonu|  25|         4| 45000|                      27|\n",
            "|   null|null|      null| 35000|                    null|\n",
            "|   null|  36|        10| 38000|                      38|\n",
            "+-------+----+----------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.drop('Experience After 2 years')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBw3K0vlR6DK",
        "outputId": "a19d4d81-523b-487c-f16a-a6921d11f365"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, Age: int, Experience: int, Salary: int]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumnRenamed('Name', 'New Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ggd9KLR5-Y",
        "outputId": "9e6c28c2-e2d7-4080-96a0-0796f340cbea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn3PrhjqR6Av",
        "outputId": "ed2785cf-db4e-4a67-fadf-9a8a63ec1790"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|    _c0|_c1|\n",
            "+-------+---+\n",
            "|   name|age|\n",
            "|prajwal| 23|\n",
            "| vishal| 25|\n",
            "|  pooja| 29|\n",
            "| sushma| 48|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3fCFZXK-SZ7",
        "outputId": "c630645f-d91b-4432-fd68-27e41b7393bc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|Prajwal|  23|         6| 60000|\n",
            "| Vishal|  26|         8| 50000|\n",
            "|  pooja|  29|         7|  4000|\n",
            "| Sushma|  48|        15|  null|\n",
            "| nayana|  23|         2| 30000|\n",
            "| Bacchu|   4|      null|  null|\n",
            "|   Sonu|  25|         4| 45000|\n",
            "|   null|null|      null| 35000|\n",
            "|   null|  36|        10| 38000|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezHijn3l-Sf5",
        "outputId": "4864ba91-8142-4738-864c-a19573ed7042"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|Prajwal| 23|         6| 60000|\n",
            "| Vishal| 26|         8| 50000|\n",
            "|  pooja| 29|         7|  4000|\n",
            "| nayana| 23|         2| 30000|\n",
            "|   Sonu| 25|         4| 45000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.drop(how='all').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkL4XB80-SjD",
        "outputId": "90257471-373c-4e9d-eb06-8d351687777a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|Prajwal|  23|         6| 60000|\n",
            "| Vishal|  26|         8| 50000|\n",
            "|  pooja|  29|         7|  4000|\n",
            "| Sushma|  48|        15|  null|\n",
            "| nayana|  23|         2| 30000|\n",
            "| Bacchu|   4|      null|  null|\n",
            "|   Sonu|  25|         4| 45000|\n",
            "|   null|null|      null| 35000|\n",
            "|   null|  36|        10| 38000|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.drop(how='any', thresh=3).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLLXQBlj-SnW",
        "outputId": "0443eafd-3855-4805-d7de-daa796c8ce14"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|Prajwal| 23|         6| 60000|\n",
            "| Vishal| 26|         8| 50000|\n",
            "|  pooja| 29|         7|  4000|\n",
            "| Sushma| 48|        15|  null|\n",
            "| nayana| 23|         2| 30000|\n",
            "|   Sonu| 25|         4| 45000|\n",
            "|   null| 36|        10| 38000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.na.drop(how='any', thresh=3, subset=['Experience']).show()"
      ],
      "metadata": {
        "id": "TLgDgU5g-SqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02adfbac-8615-4702-94c2-64aa625590d7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+----------+------+\n",
            "|Name|Age|Experience|Salary|\n",
            "+----+---+----------+------+\n",
            "+----+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling the missing values\n",
        "df_pyspark2.na.fill('Missing values', ['Experience','Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpjRSIj6-Sta",
        "outputId": "ed7d04c7-3825-4e68-8ce5-40789a9ceb2f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|Prajwal|  23|         6| 60000|\n",
            "| Vishal|  26|         8| 50000|\n",
            "|  pooja|  29|         7|  4000|\n",
            "| Sushma|  48|        15|  null|\n",
            "| nayana|  23|         2| 30000|\n",
            "| Bacchu|   4|      null|  null|\n",
            "|   Sonu|  25|         4| 45000|\n",
            "|   null|null|      null| 35000|\n",
            "|   null|  36|        10| 38000|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols = ['Age', 'Experience', 'Salary'],\n",
        "    outputCols = [\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "6EpWeyUK-SzB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation col to df\n",
        "\n",
        "imputer.fit(df_pyspark2).transform(df_pyspark2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8FXQTku-S2I",
        "outputId": "d78ef66f-ea84-4c08-e44b-857efc92b12e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "|   Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "|Prajwal|  23|         6| 60000|         23|                 6|         60000|\n",
            "| Vishal|  26|         8| 50000|         26|                 8|         50000|\n",
            "|  pooja|  29|         7|  4000|         29|                 7|          4000|\n",
            "| Sushma|  48|        15|  null|         48|                15|         37428|\n",
            "| nayana|  23|         2| 30000|         23|                 2|         30000|\n",
            "| Bacchu|   4|      null|  null|          4|                 7|         37428|\n",
            "|   Sonu|  25|         4| 45000|         25|                 4|         45000|\n",
            "|   null|null|      null| 35000|         26|                 7|         35000|\n",
            "|   null|  36|        10| 38000|         36|                10|         38000|\n",
            "+-------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pyspark Dataframe\n",
        "* Filter operation\n",
        "* &,|,==\n",
        "* ~"
      ],
      "metadata": {
        "id": "tB-OfST4OA1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.filter(df_pyspark2['Salary'] > 35000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRvBLFY7-S7s",
        "outputId": "4fe2c548-9006-477d-b18a-f404dac943ee"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|Age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|Prajwal| 23|         6| 60000|\n",
            "| Vishal| 26|         8| 50000|\n",
            "|   Sonu| 25|         4| 45000|\n",
            "|   null| 36|        10| 38000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.filter(~(df_pyspark2['Salary'] > 35000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoeH5c7ZRlA4",
        "outputId": "0cd809b6-e200-4dac-8f72-dd5940170dcb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----------+------+\n",
            "|  Name| Age|Experience|Salary|\n",
            "+------+----+----------+------+\n",
            "| pooja|  29|         7|  4000|\n",
            "|nayana|  23|         2| 30000|\n",
            "|  null|null|      null| 35000|\n",
            "+------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.filter('Salary > 35000').select(['Name', 'Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63b5lqtT-S_q",
        "outputId": "db15997f-3ae4-435f-b4b8-31b33a344b35"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|Age|\n",
            "+-------+---+\n",
            "|Prajwal| 23|\n",
            "| Vishal| 26|\n",
            "|   Sonu| 25|\n",
            "|   null| 36|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.filter((df_pyspark2['Salary'] > 35000) & (df_pyspark2['Salary'] < 60000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yp04XlL-TCx",
        "outputId": "347a15fa-10ed-4839-9f75-a66e5902b684"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+----------+------+\n",
            "|  Name|Age|Experience|Salary|\n",
            "+------+---+----------+------+\n",
            "|Vishal| 26|         8| 50000|\n",
            "|  Sonu| 25|         4| 45000|\n",
            "|  null| 36|        10| 38000|\n",
            "+------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.filter((df_pyspark2['Salary'] > 35000) | (df_pyspark2['Salary'] < 60000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtFNguF6-TFi",
        "outputId": "8d4113be-c7e3-47db-f940-0060c63bcd77"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+----------+------+\n",
            "|   Name| Age|Experience|Salary|\n",
            "+-------+----+----------+------+\n",
            "|Prajwal|  23|         6| 60000|\n",
            "| Vishal|  26|         8| 50000|\n",
            "|  pooja|  29|         7|  4000|\n",
            "| nayana|  23|         2| 30000|\n",
            "|   Sonu|  25|         4| 45000|\n",
            "|   null|null|      null| 35000|\n",
            "|   null|  36|        10| 38000|\n",
            "+-------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.groupBy('Age').sum().show()"
      ],
      "metadata": {
        "id": "wf66KnSd-TI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bd0b27-aab8-4b09-8afb-263e6cdc5a03"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+---------------+-----------+\n",
            "| Age|sum(Age)|sum(Experience)|sum(Salary)|\n",
            "+----+--------+---------------+-----------+\n",
            "|  26|      26|              8|      50000|\n",
            "|null|    null|           null|      35000|\n",
            "|  48|      48|             15|       null|\n",
            "|   4|       4|           null|       null|\n",
            "|  23|      46|              8|      90000|\n",
            "|  25|      25|              4|      45000|\n",
            "|  29|      29|              7|       4000|\n",
            "|  36|      36|             10|      38000|\n",
            "+----+--------+---------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark2.agg({'Salary' : 'sum'}).show()"
      ],
      "metadata": {
        "id": "uWoNqkH3-TMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc98a23c-40f1-45f8-db6e-bcc58ac1a2bf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|     262000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLlib** is Apache Spark's scalable machine learning library.\n",
        "\n",
        "In spark Ml there are two different techniques\n",
        "\n",
        "* RDD\n",
        "* DataFrame APIs"
      ],
      "metadata": {
        "id": "RYpjP5v0wd9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark1.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmA9KZL01mTe",
        "outputId": "1a9cc24e-3235-4d92-d124-405dfdb1e76d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'Age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols = [\"Age\",\"Experience\"], outputCol = \"Independent Feature\")"
      ],
      "metadata": {
        "id": "AiRvPlXb-TPH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = assembler.transform(df_pyspark1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "ZIN2FC7acVpG",
        "outputId": "9833eb60-f52c-454f-8882-db483f321b80"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-1873f7786c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massembler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pyspark1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: Data type string of column Age is not supported.\nData type string of column Experience is not supported."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.show()"
      ],
      "metadata": {
        "id": "8AzY6MEu-TVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data=output.select(\"Independent Features\",\"Salary\")"
      ],
      "metadata": {
        "id": "hleZ9BCZ-TYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data.show()"
      ],
      "metadata": {
        "id": "dlt9TSCc-Tgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Databricks are actually helps us to perform data engineering.\n",
        "\n",
        "Data engineering means probabilie working with big data."
      ],
      "metadata": {
        "id": "1hCOn5HKDiZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "##train test split\n",
        "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
        "regressor=LinearRegression(featuresCol='Independent Features', labelCol='Salary')\n",
        "regressor=regressor.fit(train_data)"
      ],
      "metadata": {
        "id": "hzKZMbuT-Tjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Coefficients\n",
        "regressor.coefficients"
      ],
      "metadata": {
        "id": "aq0gGIBB-Tmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Intercepts\n",
        "regressor.intercept"
      ],
      "metadata": {
        "id": "VJMHFY57-Tpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Prediction\n",
        "pred_results=regressor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "zOKhD5Ev-Tut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.predictions.show()"
      ],
      "metadata": {
        "id": "Th3v3QDGR57m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
      ],
      "metadata": {
        "id": "SLq0C4DNR55w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAH2P6M5R52a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7deVl8cWR5ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tPstIctOR5w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGOSGF4eR3y4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}